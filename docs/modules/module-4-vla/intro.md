---
title: Module 4 - VLA (Vision–Language–Action)
sidebar_class_name: module-index
sidebar_position: 4
description: The cutting edge of Physical AI - Vision-Language-Action models.
---

# Module 4: VLA (Vision–Language–Action)

Welcome to Module 4! This module covers the frontier of Physical AI: VLA models.

## Learning Objectives

- Understand multimodal foundation models in robotics.
- Connecting Vision (V) and Language (L) to Action (A).
- Case studies: RT-2, PaLM-E, and others.

## Chapters

1. **[Foundations of VLA](./chapters/01-vla-foundations.md)**: From LLMs to VLAs.

## Labs

- Lab 4.1: Interacting with a VLA Model
- Lab 4.2: Simple Instruction Following Task

## Summary

VLA models represent the convergence of advanced AI and robotics, enabling robots to understand and act upon natural language in complex environments.

## What's Next?

Dive into the [Foundations of VLA](./chapters/01-vla-foundations.md) to understand how these models work.